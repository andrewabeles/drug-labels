{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0258893-1a41-4d3b-b8ff-06f754ad917b",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41329636-4564-4e06-a294-7d8b3b56c6af",
   "metadata": {},
   "source": [
    "This code trains a Naive Bayes classifier on the processed text to predict a drug's route of administration. The final model will be saved to the models/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01ba92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f5ed33",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca7edb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...</td>\n",
       "      <td>[adults, take, pellets, mouth, three, times, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DIRECTIONS Adults: Dissolve 3 to 5 under the t...</td>\n",
       "      <td>[adults, dissolve, tongue, three, times, day, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPHTHALMIC</td>\n",
       "      <td>DOSAGE AND ADMINISTRATION The recommended dosa...</td>\n",
       "      <td>[recommended, regimen, treatment, bacterial, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>2 DOSAGE AND ADMINISTRATION Use the lowest eff...</td>\n",
       "      <td>[use, lowest, effective, shortest, duration, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPICAL</td>\n",
       "      <td>Directions wet face, apply to hand, massage fa...</td>\n",
       "      <td>[wet, face, apply, hand, massage, face, gently...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text  \\\n",
       "0        ORAL  DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...   \n",
       "1        ORAL  DIRECTIONS Adults: Dissolve 3 to 5 under the t...   \n",
       "2  OPHTHALMIC  DOSAGE AND ADMINISTRATION The recommended dosa...   \n",
       "3        ORAL  2 DOSAGE AND ADMINISTRATION Use the lowest eff...   \n",
       "4     TOPICAL  Directions wet face, apply to hand, massage fa...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [adults, take, pellets, mouth, three, times, d...  \n",
       "1  [adults, dissolve, tongue, three, times, day, ...  \n",
       "2  [recommended, regimen, treatment, bacterial, c...  \n",
       "3  [use, lowest, effective, shortest, duration, c...  \n",
       "4  [wet, face, apply, hand, massage, face, gently...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/processed/drugs.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7b8bcc",
   "metadata": {},
   "source": [
    "## Classifier Prep - Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb835c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORAL',\n",
       " 'OPHTHALMIC',\n",
       " 'TOPICAL',\n",
       " 'INTRAVENOUS',\n",
       " 'RESPIRATORY (INHALATION)',\n",
       " 'VAGINAL',\n",
       " 'SUBLINGUAL',\n",
       " 'INTRAMUSCULAR',\n",
       " 'DENTAL',\n",
       " 'IRRIGATION',\n",
       " 'INTRATHECAL',\n",
       " 'EPIDURAL',\n",
       " 'SUBCUTANEOUS',\n",
       " 'NASAL',\n",
       " 'RECTAL',\n",
       " 'CUTANEOUS',\n",
       " 'INTRA-ARTICULAR',\n",
       " 'TRANSDERMAL',\n",
       " 'INTRAOCULAR',\n",
       " 'PERCUTANEOUS',\n",
       " 'INTRACARDIAC',\n",
       " 'INTRAVITREAL',\n",
       " 'AURICULAR (OTIC)',\n",
       " 'SUBMUCOSAL',\n",
       " 'BUCCAL',\n",
       " 'PERINEURAL',\n",
       " 'INFILTRATION',\n",
       " 'INTRALESIONAL',\n",
       " 'PERIODONTAL',\n",
       " 'PARENTERAL',\n",
       " 'INTRACAVITARY',\n",
       " 'INTRAVASCULAR',\n",
       " 'ENDOTRACHEAL',\n",
       " 'INTRACAVERNOUS',\n",
       " 'EXTRACORPOREAL',\n",
       " 'INTRADERMAL',\n",
       " 'INTRA-ARTERIAL',\n",
       " 'SUBARACHNOID',\n",
       " 'INTRAUTERINE',\n",
       " 'OROPHARYNGEAL',\n",
       " 'INTRATYMPANIC',\n",
       " 'INTRACAMERAL',\n",
       " 'HEMODIALYSIS',\n",
       " 'URETHRAL',\n",
       " 'INTRAPERITONEAL',\n",
       " 'TRANSMUCOSAL',\n",
       " 'INTRAVESICAL',\n",
       " 'ENTERAL',\n",
       " 'INTRABRONCHIAL',\n",
       " 'INTRACANALICULAR',\n",
       " 'URETERAL',\n",
       " 'RETROBULBAR',\n",
       " 'INTRAPLEURAL',\n",
       " 'INTRASPINAL',\n",
       " 'SUBGINGIVAL',\n",
       " 'INTRASINAL',\n",
       " 'INTRAVENTRICULAR']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Currently, there are many labels in the target variable column.\n",
    "## 5 of these account for more than 90% of the data. As such, anything outside the top 5 labels by count\n",
    "## will be reclassified as OTHER\n",
    "\n",
    "list(df['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18416cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ORAL</th>\n",
       "      <td>46628</td>\n",
       "      <td>46628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOPICAL</th>\n",
       "      <td>27823</td>\n",
       "      <td>27823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTRAVENOUS</th>\n",
       "      <td>2857</td>\n",
       "      <td>2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENTAL</th>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTRAMUSCULAR</th>\n",
       "      <td>1378</td>\n",
       "      <td>1378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPHTHALMIC</th>\n",
       "      <td>1344</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUBLINGUAL</th>\n",
       "      <td>798</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NASAL</th>\n",
       "      <td>643</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUBCUTANEOUS</th>\n",
       "      <td>325</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESPIRATORY (INHALATION)</th>\n",
       "      <td>325</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RECTAL</th>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAGINAL</th>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRANSDERMAL</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AURICULAR (OTIC)</th>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIDURAL</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFILTRATION</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUTANEOUS</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTRA-ARTICULAR</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUCCAL</th>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXTRACORPOREAL</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           text  tokens\n",
       "target                                 \n",
       "ORAL                      46628   46628\n",
       "TOPICAL                   27823   27823\n",
       "INTRAVENOUS                2857    2857\n",
       "DENTAL                     1401    1401\n",
       "INTRAMUSCULAR              1378    1378\n",
       "OPHTHALMIC                 1344    1344\n",
       "SUBLINGUAL                  798     798\n",
       "NASAL                       643     643\n",
       "SUBCUTANEOUS                325     325\n",
       "RESPIRATORY (INHALATION)    325     325\n",
       "RECTAL                      320     320\n",
       "VAGINAL                     211     211\n",
       "TRANSDERMAL                 198     198\n",
       "AURICULAR (OTIC)            179     179\n",
       "EPIDURAL                    117     117\n",
       "INFILTRATION                103     103\n",
       "CUTANEOUS                   100     100\n",
       "INTRA-ARTICULAR              82      82\n",
       "BUCCAL                       76      76\n",
       "EXTRACORPOREAL               71      71"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## As seen below, the top 5 target values are ORAL, TOPICAL, INTRAVENOUS, DENTAL and INTRAMUSCULAR\n",
    "## All others will be converted to OTHER\n",
    "df.groupby('target') \\\n",
    "   .count() \\\n",
    "   .sort_values('text', ascending=False) \\\n",
    "   .head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1458bf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORAL', 'OTHER', 'TOPICAL', 'INTRAVENOUS', 'INTRAMUSCULAR', 'DENTAL']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[~df['target'].isin(['ORAL', 'TOPICAL', 'INTRAVENOUS', 'DENTAL', 'INTRAMUSCULAR']), 'target'] = 'OTHER'\n",
    "\n",
    "list(df['target'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb3f20d",
   "metadata": {},
   "source": [
    "## Classifier Prep - Feature Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dff0ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...</td>\n",
       "      <td>[adults, take, pellets, mouth, three, times, d...</td>\n",
       "      <td>adults take pellets mouth three times daily su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DIRECTIONS Adults: Dissolve 3 to 5 under the t...</td>\n",
       "      <td>[adults, dissolve, tongue, three, times, day, ...</td>\n",
       "      <td>adults dissolve tongue three times day directe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>DOSAGE AND ADMINISTRATION The recommended dosa...</td>\n",
       "      <td>[recommended, regimen, treatment, bacterial, c...</td>\n",
       "      <td>recommended regimen treatment bacterial conjun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>2 DOSAGE AND ADMINISTRATION Use the lowest eff...</td>\n",
       "      <td>[use, lowest, effective, shortest, duration, c...</td>\n",
       "      <td>use lowest effective shortest duration consist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPICAL</td>\n",
       "      <td>Directions wet face, apply to hand, massage fa...</td>\n",
       "      <td>[wet, face, apply, hand, massage, face, gently...</td>\n",
       "      <td>wet face apply hand massage face gently rinse ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                                               text  \\\n",
       "0     ORAL  DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...   \n",
       "1     ORAL  DIRECTIONS Adults: Dissolve 3 to 5 under the t...   \n",
       "2    OTHER  DOSAGE AND ADMINISTRATION The recommended dosa...   \n",
       "3     ORAL  2 DOSAGE AND ADMINISTRATION Use the lowest eff...   \n",
       "4  TOPICAL  Directions wet face, apply to hand, massage fa...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [adults, take, pellets, mouth, three, times, d...   \n",
       "1  [adults, dissolve, tongue, three, times, day, ...   \n",
       "2  [recommended, regimen, treatment, bacterial, c...   \n",
       "3  [use, lowest, effective, shortest, duration, c...   \n",
       "4  [wet, face, apply, hand, massage, face, gently...   \n",
       "\n",
       "                                          tokens_str  \n",
       "0  adults take pellets mouth three times daily su...  \n",
       "1  adults dissolve tongue three times day directe...  \n",
       "2  recommended regimen treatment bacterial conjun...  \n",
       "3  use lowest effective shortest duration consist...  \n",
       "4  wet face apply hand massage face gently rinse ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Covnert final tokens column in df into a list of key-value pairs containing text tokens (as string) and \n",
    "## the target variable\n",
    "\n",
    "df['tokens_str'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f4a8077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['years age ask doctor use studies done show product work using product read enclosed userâ€™s guide complete important information begin using lozenge quit day smoke first cigarette minutes waking use mg nicotine lozenge smoke first cigarette within minutes waking use mg nicotine lozenge according following week schedule weeks weeks weeks lozenge every hours lozenge every hours lozenge every hours nicotine lozenge medicine must used certain way get best results place lozenge mouth allow lozenge slowly dissolve minutes minimize swallowing chew swallow lozenge may feel warm tingling sensation occasionally move lozenge one side mouth completely dissolved minutes eat drink minutes using lozenge mouth improve chances quitting use least lozenges per day first weeks use one lozenge time continuously use one lozenge another since may cause hiccups heartburn nausea side effects use lozenges hours use lozenges per day important complete treatment feel need use lozenge longer period keep smoking talk health care provider',\n",
       "  'ORAL'],\n",
       " ['spray liberally spread evenly hand minutes sun exposure hold inches away skin apply spray directly face spray hands apply face apply windy conditions use wellventilated area reapply minutes swimming sweating immediately towel drying least every hours children months age ask doctor sun protection measures spending time sun increases risk skin cancer early skin aging decrease risk regularly use sunscreen broad spectrum spf value higher sun protection measures including limit time sun especially pm wear longsleeved shirts pants hats sunglasses',\n",
       "  'TOPICAL'],\n",
       " ['take directed see overdose warning adults children years take caplets every hours water swallow whole crush chew split dissolve take caplets hours use days unless directed doctor children years use',\n",
       "  'ORAL'],\n",
       " ['take times daily ages older drops ages drops age consult doctor', 'ORAL'],\n",
       " ['adults dissolve tongue three times day directed lic practitioner take greater intervals condition subsides children dissolve tongue three times day directed lic practitioner take greater intervals condition subsides',\n",
       "  'ORAL']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs_data = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    tokens = df['tokens_str'][i]\n",
    "    target = df['target'][i]\n",
    "    \n",
    "    drugs_data.append([tokens, target])\n",
    "\n",
    "random.choices(drugs_data,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c10f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 15810 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "tokens = [w for t, p in drugs_data for w in t.split()]\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "feature_words = set()\n",
    "\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7939cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text) :\n",
    "    \"\"\" Splitting on whitespace. \"\"\"\n",
    "    \n",
    "    tk = WhitespaceTokenizer()\n",
    "    final_text = tk.tokenize(text)\n",
    "    \n",
    "    return(final_text)\n",
    "\n",
    "\n",
    "\n",
    "def drugs_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "    feature words.\n",
    "    Args:\n",
    "    * text: a piece of text in a continuous string. Assumes\n",
    "    text has been cleaned and case folded.\n",
    "    * fw: the *feature words* that we're considering. A word\n",
    "    in `text` must be in fw in order to be returned. This\n",
    "    prevents us from considering very rarely occurring words.\n",
    "    Returns:\n",
    "    A dictionary with the words in `text` that appear in `fw`.\n",
    "    Words are only counted once.\n",
    "    If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "    then this would return a dictionary of\n",
    "    {'quick' : True,\n",
    "    'fox' : True}\n",
    "    \"\"\"\n",
    "    dict_list =[]\n",
    "    tokens = tokenize(text)\n",
    "\n",
    "    for i in tokens:\n",
    "        if i in fw:\n",
    "            dict_list.append([i, True])\n",
    "\n",
    "    ret_dict = dict(dict_list)\n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0346cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(drugs_features(text,feature_words), target) for (text, target) in drugs_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde5343",
   "metadata": {},
   "source": [
    "## Classifier - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "376e79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b0d3ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93ef85e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  stable = True           INTRAV : TOPICA =   5773.3 : 1.0\n",
      "                 reapply = True           TOPICA : ORAL   =   5678.6 : 1.0\n",
      "                      iv = True           INTRAM : TOPICA =   5671.7 : 1.0\n",
      "                swimming = True           TOPICA : ORAL   =   5494.4 : 1.0\n",
      "                injected = True           INTRAM : TOPICA =   5389.8 : 1.0\n",
      "                 diluted = True           INTRAV : TOPICA =   5323.3 : 1.0\n",
      "                   aging = True           TOPICA : ORAL   =   4970.6 : 1.0\n",
      "                spectrum = True           TOPICA : ORAL   =   4598.6 : 1.0\n",
      "          reconstitution = True           INTRAV : TOPICA =   4483.1 : 1.0\n",
      "                lactated = True           INTRAV : TOPICA =   4308.1 : 1.0\n",
      "          individualized = True           INTRAM : TOPICA =   4168.2 : 1.0\n",
      "                     rub = True           TOPICA : ORAL   =   4052.5 : 1.0\n",
      "                 divided = True           INTRAM : TOPICA =   4047.4 : 1.0\n",
      "                 tablets = True             ORAL : TOPICA =   3500.7 : 1.0\n",
      "                     sun = True           TOPICA : ORAL   =   3455.4 : 1.0\n",
      "                  caries = True           DENTAL : ORAL   =   3417.4 : 1.0\n",
      "            refrigerated = True           INTRAV : TOPICA =   3283.7 : 1.0\n",
      "                   acute = True           INTRAM : TOPICA =   3266.1 : 1.0\n",
      "           precipitation = True           INTRAM : TOPICA =   3228.5 : 1.0\n",
      "           postoperative = True           INTRAM : TOPICA =   3067.4 : 1.0\n",
      "                    bags = True           INTRAV : TOPICA =   2959.6 : 1.0\n",
      "                   heart = True           INTRAV : TOPICA =   2849.4 : 1.0\n",
      "                 hepatic = True           INTRAV : TOPICA =   2836.4 : 1.0\n",
      "                  fluids = True           INTRAV : TOPICA =   2810.5 : 1.0\n",
      "           discoloration = True           INTRAV : TOPICA =   2772.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ce37388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORAL', 'OTHER', 'TOPICAL', 'INTRAVENOUS', 'INTRAMUSCULAR', 'DENTAL']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8585defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual drug category vs. predicted / classified. \n",
    "# first key is actual, second is estimated\n",
    "drug_types = list(df['target'].unique())\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for d in drug_types :\n",
    "    for d1 in drug_types :\n",
    "        results[d][d1] = 0\n",
    "        \n",
    "random.shuffle(drugs_data)\n",
    "\n",
    "for idx, dd in enumerate(drugs_data) :\n",
    "    text, target = dd\n",
    "    estimated_party = classifier.classify(drugs_features(text, feature_words))\n",
    "    results[target][estimated_party] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "493e3ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'ORAL': defaultdict(int,\n",
       "                         {'ORAL': 29331,\n",
       "                          'OTHER': 370,\n",
       "                          'TOPICAL': 13,\n",
       "                          'INTRAVENOUS': 10606,\n",
       "                          'INTRAMUSCULAR': 5745,\n",
       "                          'DENTAL': 563}),\n",
       "             'OTHER': defaultdict(int,\n",
       "                         {'ORAL': 406,\n",
       "                          'OTHER': 3332,\n",
       "                          'TOPICAL': 104,\n",
       "                          'INTRAVENOUS': 929,\n",
       "                          'INTRAMUSCULAR': 464,\n",
       "                          'DENTAL': 6}),\n",
       "             'TOPICAL': defaultdict(int,\n",
       "                         {'ORAL': 250,\n",
       "                          'OTHER': 3103,\n",
       "                          'TOPICAL': 22135,\n",
       "                          'INTRAVENOUS': 1412,\n",
       "                          'INTRAMUSCULAR': 783,\n",
       "                          'DENTAL': 140}),\n",
       "             'INTRAVENOUS': defaultdict(int,\n",
       "                         {'ORAL': 0,\n",
       "                          'OTHER': 1,\n",
       "                          'TOPICAL': 0,\n",
       "                          'INTRAVENOUS': 2744,\n",
       "                          'INTRAMUSCULAR': 112,\n",
       "                          'DENTAL': 0}),\n",
       "             'INTRAMUSCULAR': defaultdict(int,\n",
       "                         {'ORAL': 0,\n",
       "                          'OTHER': 0,\n",
       "                          'TOPICAL': 0,\n",
       "                          'INTRAVENOUS': 43,\n",
       "                          'INTRAMUSCULAR': 1335,\n",
       "                          'DENTAL': 0}),\n",
       "             'DENTAL': defaultdict(int,\n",
       "                         {'ORAL': 75,\n",
       "                          'OTHER': 24,\n",
       "                          'TOPICAL': 4,\n",
       "                          'INTRAVENOUS': 12,\n",
       "                          'INTRAMUSCULAR': 4,\n",
       "                          'DENTAL': 1282})})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd1123",
   "metadata": {},
   "source": [
    "## Output Model -> Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce9a900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trained model now being output to pickle file - allowing it to be applied to new test cases in Dash app.\n",
    "with open('../models/classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(classifier, f)\n",
    "with open('../models/classifier_features.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4f86b-fac6-4ff7-b277-702aefeb91b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
